{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6bf6d3a",
   "metadata": {
    "id": "d6bf6d3a"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29843b90",
   "metadata": {
    "id": "29843b90"
   },
   "source": [
    "<h2> Feature Selection on Autism Biolog Dataset</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2aa2b8",
   "metadata": {
    "id": "1d2aa2b8"
   },
   "source": [
    "<h3>Loading the Data</h3>\n",
    "\n",
    "\n",
    "1. Loaded the dataset \n",
    "2. Drop the Columns which aren't required\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d4647c3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "id": "5d4647c3",
    "outputId": "9e59874c-63f9-4c99-a065-588910b82f5d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a-Cyclodextrin</th>\n",
       "      <th>Dextrin</th>\n",
       "      <th>Glycogen</th>\n",
       "      <th>Maltitol</th>\n",
       "      <th>Maltotriose</th>\n",
       "      <th>Maltose</th>\n",
       "      <th>D-Trehalose</th>\n",
       "      <th>D-Cellobiose</th>\n",
       "      <th>Gentiobiose</th>\n",
       "      <th>D-Glucose-6-Phosphate</th>\n",
       "      <th>...</th>\n",
       "      <th>Adenosine.4</th>\n",
       "      <th>Adenosine.5</th>\n",
       "      <th>Adenosine.6</th>\n",
       "      <th>Gly-His-Lys acetate salt</th>\n",
       "      <th>Gly-His-Lys acetate salt.1</th>\n",
       "      <th>Gly-His-Lys acetate salt.2</th>\n",
       "      <th>Gly-His-Lys acetate salt.3</th>\n",
       "      <th>Gly-His-Lys acetate salt.4</th>\n",
       "      <th>Gly-His-Lys acetate salt.5</th>\n",
       "      <th>Diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.262591</td>\n",
       "      <td>0.997133</td>\n",
       "      <td>0.986968</td>\n",
       "      <td>0.277475</td>\n",
       "      <td>1.074956</td>\n",
       "      <td>1.089453</td>\n",
       "      <td>0.405887</td>\n",
       "      <td>0.311380</td>\n",
       "      <td>0.353178</td>\n",
       "      <td>0.455127</td>\n",
       "      <td>...</td>\n",
       "      <td>1.102738</td>\n",
       "      <td>1.095119</td>\n",
       "      <td>1.080465</td>\n",
       "      <td>0.997059</td>\n",
       "      <td>1.088651</td>\n",
       "      <td>0.986823</td>\n",
       "      <td>0.97434</td>\n",
       "      <td>0.951473</td>\n",
       "      <td>0.869257</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.239292</td>\n",
       "      <td>0.911528</td>\n",
       "      <td>1.013144</td>\n",
       "      <td>0.300022</td>\n",
       "      <td>1.022068</td>\n",
       "      <td>1.135745</td>\n",
       "      <td>0.392186</td>\n",
       "      <td>0.324281</td>\n",
       "      <td>0.310849</td>\n",
       "      <td>0.463682</td>\n",
       "      <td>...</td>\n",
       "      <td>1.181000</td>\n",
       "      <td>1.122300</td>\n",
       "      <td>1.235600</td>\n",
       "      <td>0.963800</td>\n",
       "      <td>0.943900</td>\n",
       "      <td>0.919300</td>\n",
       "      <td>0.90680</td>\n",
       "      <td>0.933600</td>\n",
       "      <td>0.886200</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.312369</td>\n",
       "      <td>1.408409</td>\n",
       "      <td>1.419281</td>\n",
       "      <td>0.379099</td>\n",
       "      <td>0.362415</td>\n",
       "      <td>0.169417</td>\n",
       "      <td>0.256599</td>\n",
       "      <td>0.111319</td>\n",
       "      <td>0.167910</td>\n",
       "      <td>0.617430</td>\n",
       "      <td>...</td>\n",
       "      <td>1.322800</td>\n",
       "      <td>0.753800</td>\n",
       "      <td>0.699300</td>\n",
       "      <td>1.188000</td>\n",
       "      <td>1.210800</td>\n",
       "      <td>1.121900</td>\n",
       "      <td>1.06560</td>\n",
       "      <td>1.046800</td>\n",
       "      <td>0.711000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.188019</td>\n",
       "      <td>0.592031</td>\n",
       "      <td>0.413213</td>\n",
       "      <td>0.170653</td>\n",
       "      <td>0.253267</td>\n",
       "      <td>0.182602</td>\n",
       "      <td>0.158959</td>\n",
       "      <td>0.146343</td>\n",
       "      <td>0.134804</td>\n",
       "      <td>0.329473</td>\n",
       "      <td>...</td>\n",
       "      <td>0.615300</td>\n",
       "      <td>0.669000</td>\n",
       "      <td>0.572100</td>\n",
       "      <td>0.641000</td>\n",
       "      <td>0.633900</td>\n",
       "      <td>0.622100</td>\n",
       "      <td>0.61450</td>\n",
       "      <td>0.576700</td>\n",
       "      <td>0.546200</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.253399</td>\n",
       "      <td>1.352917</td>\n",
       "      <td>0.949392</td>\n",
       "      <td>0.251156</td>\n",
       "      <td>0.444184</td>\n",
       "      <td>0.218518</td>\n",
       "      <td>0.137328</td>\n",
       "      <td>0.174540</td>\n",
       "      <td>0.155979</td>\n",
       "      <td>0.680785</td>\n",
       "      <td>...</td>\n",
       "      <td>1.401038</td>\n",
       "      <td>1.367023</td>\n",
       "      <td>1.305691</td>\n",
       "      <td>1.234141</td>\n",
       "      <td>1.515057</td>\n",
       "      <td>1.158642</td>\n",
       "      <td>1.21869</td>\n",
       "      <td>1.183060</td>\n",
       "      <td>1.089372</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 735 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   a-Cyclodextrin   Dextrin  Glycogen  Maltitol  Maltotriose   Maltose  \\\n",
       "0        0.262591  0.997133  0.986968  0.277475     1.074956  1.089453   \n",
       "1        0.239292  0.911528  1.013144  0.300022     1.022068  1.135745   \n",
       "2        0.312369  1.408409  1.419281  0.379099     0.362415  0.169417   \n",
       "3        0.188019  0.592031  0.413213  0.170653     0.253267  0.182602   \n",
       "4        0.253399  1.352917  0.949392  0.251156     0.444184  0.218518   \n",
       "\n",
       "   D-Trehalose  D-Cellobiose  Gentiobiose  D-Glucose-6-Phosphate  ...  \\\n",
       "0     0.405887      0.311380     0.353178               0.455127  ...   \n",
       "1     0.392186      0.324281     0.310849               0.463682  ...   \n",
       "2     0.256599      0.111319     0.167910               0.617430  ...   \n",
       "3     0.158959      0.146343     0.134804               0.329473  ...   \n",
       "4     0.137328      0.174540     0.155979               0.680785  ...   \n",
       "\n",
       "   Adenosine.4  Adenosine.5  Adenosine.6  Gly-His-Lys acetate salt  \\\n",
       "0     1.102738     1.095119     1.080465                  0.997059   \n",
       "1     1.181000     1.122300     1.235600                  0.963800   \n",
       "2     1.322800     0.753800     0.699300                  1.188000   \n",
       "3     0.615300     0.669000     0.572100                  0.641000   \n",
       "4     1.401038     1.367023     1.305691                  1.234141   \n",
       "\n",
       "   Gly-His-Lys acetate salt.1  Gly-His-Lys acetate salt.2  \\\n",
       "0                    1.088651                    0.986823   \n",
       "1                    0.943900                    0.919300   \n",
       "2                    1.210800                    1.121900   \n",
       "3                    0.633900                    0.622100   \n",
       "4                    1.515057                    1.158642   \n",
       "\n",
       "   Gly-His-Lys acetate salt.3  Gly-His-Lys acetate salt.4  \\\n",
       "0                     0.97434                    0.951473   \n",
       "1                     0.90680                    0.933600   \n",
       "2                     1.06560                    1.046800   \n",
       "3                     0.61450                    0.576700   \n",
       "4                     1.21869                    1.183060   \n",
       "\n",
       "   Gly-His-Lys acetate salt.5  Diagnosis  \n",
       "0                    0.869257          1  \n",
       "1                    0.886200          1  \n",
       "2                    0.711000          1  \n",
       "3                    0.546200          1  \n",
       "4                    1.089372          1  \n",
       "\n",
       "[5 rows x 735 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # read the csv file from the link provided\n",
    " # drop Negative Controls from the dataset, since Negative Controls are not needed\n",
    " # drop the column that is not required from the dataset(CMS#)\n",
    "\n",
    "df = pd.read_csv(\"C:/AutisticDisorderProject/TestTrain5050data.csv\")\n",
    "df.drop(list(df.filter(regex='Negative Control')), axis=1, inplace=True)\n",
    "\n",
    "\n",
    "asd_data = df.drop(columns='CMS#',axis=1)\n",
    "# drop the 'CMS' column\n",
    "\n",
    "asd_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48881774",
   "metadata": {
    "id": "48881774"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 735)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# strip the whitespace in the column names\n",
    "asd_data.columns = asd_data.columns.str.strip()\n",
    "asd_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ddda51",
   "metadata": {
    "id": "c5ddda51"
   },
   "source": [
    "<h3>Scaling the Data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4efdc72",
   "metadata": {
    "id": "a4efdc72"
   },
   "outputs": [],
   "source": [
    "# hint: Use MinMaxScaler for scaling\n",
    "def scale_data(data):\n",
    "    # store all the columns\n",
    "    cols = data.columns\n",
    "    # create a scaler\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    \n",
    "    # fit and transform the data\n",
    "    scaled_data = scaler.fit_transform(data)\n",
    "    \n",
    "    # store the transformed data in a dataframe and return it.\n",
    "    transformed_data = pd.DataFrame(scaled_data)\n",
    "    transformed_data.columns = cols\n",
    "    return transformed_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c618794d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "id": "c618794d",
    "outputId": "be068134-df65-4bae-c819-fe5e2c2c7967"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a-Cyclodextrin</th>\n",
       "      <th>Dextrin</th>\n",
       "      <th>Glycogen</th>\n",
       "      <th>Maltitol</th>\n",
       "      <th>Maltotriose</th>\n",
       "      <th>Maltose</th>\n",
       "      <th>D-Trehalose</th>\n",
       "      <th>D-Cellobiose</th>\n",
       "      <th>Gentiobiose</th>\n",
       "      <th>D-Glucose-6-Phosphate</th>\n",
       "      <th>...</th>\n",
       "      <th>Adenosine.4</th>\n",
       "      <th>Adenosine.5</th>\n",
       "      <th>Adenosine.6</th>\n",
       "      <th>Gly-His-Lys acetate salt</th>\n",
       "      <th>Gly-His-Lys acetate salt.1</th>\n",
       "      <th>Gly-His-Lys acetate salt.2</th>\n",
       "      <th>Gly-His-Lys acetate salt.3</th>\n",
       "      <th>Gly-His-Lys acetate salt.4</th>\n",
       "      <th>Gly-His-Lys acetate salt.5</th>\n",
       "      <th>Diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.423145</td>\n",
       "      <td>0.611943</td>\n",
       "      <td>0.673013</td>\n",
       "      <td>0.655346</td>\n",
       "      <td>0.798260</td>\n",
       "      <td>0.741404</td>\n",
       "      <td>0.599716</td>\n",
       "      <td>0.665656</td>\n",
       "      <td>0.754709</td>\n",
       "      <td>0.489498</td>\n",
       "      <td>...</td>\n",
       "      <td>0.553747</td>\n",
       "      <td>0.529862</td>\n",
       "      <td>0.554927</td>\n",
       "      <td>0.580709</td>\n",
       "      <td>0.632509</td>\n",
       "      <td>0.616020</td>\n",
       "      <td>0.553273</td>\n",
       "      <td>0.584858</td>\n",
       "      <td>0.574413</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.354959</td>\n",
       "      <td>0.554366</td>\n",
       "      <td>0.692812</td>\n",
       "      <td>0.725226</td>\n",
       "      <td>0.754946</td>\n",
       "      <td>0.775075</td>\n",
       "      <td>0.575320</td>\n",
       "      <td>0.703234</td>\n",
       "      <td>0.652358</td>\n",
       "      <td>0.503952</td>\n",
       "      <td>...</td>\n",
       "      <td>0.597941</td>\n",
       "      <td>0.544887</td>\n",
       "      <td>0.644687</td>\n",
       "      <td>0.558909</td>\n",
       "      <td>0.537492</td>\n",
       "      <td>0.568644</td>\n",
       "      <td>0.508922</td>\n",
       "      <td>0.573468</td>\n",
       "      <td>0.585870</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.568819</td>\n",
       "      <td>0.888562</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.970318</td>\n",
       "      <td>0.214713</td>\n",
       "      <td>0.072198</td>\n",
       "      <td>0.333904</td>\n",
       "      <td>0.082914</td>\n",
       "      <td>0.306733</td>\n",
       "      <td>0.763727</td>\n",
       "      <td>...</td>\n",
       "      <td>0.678014</td>\n",
       "      <td>0.341184</td>\n",
       "      <td>0.334388</td>\n",
       "      <td>0.705864</td>\n",
       "      <td>0.712690</td>\n",
       "      <td>0.710792</td>\n",
       "      <td>0.613200</td>\n",
       "      <td>0.645610</td>\n",
       "      <td>0.467408</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.204909</td>\n",
       "      <td>0.339476</td>\n",
       "      <td>0.239045</td>\n",
       "      <td>0.324258</td>\n",
       "      <td>0.125324</td>\n",
       "      <td>0.081788</td>\n",
       "      <td>0.160053</td>\n",
       "      <td>0.184931</td>\n",
       "      <td>0.226685</td>\n",
       "      <td>0.277191</td>\n",
       "      <td>...</td>\n",
       "      <td>0.278496</td>\n",
       "      <td>0.294307</td>\n",
       "      <td>0.260791</td>\n",
       "      <td>0.347324</td>\n",
       "      <td>0.334002</td>\n",
       "      <td>0.360123</td>\n",
       "      <td>0.316979</td>\n",
       "      <td>0.346016</td>\n",
       "      <td>0.355979</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.396242</td>\n",
       "      <td>0.851239</td>\n",
       "      <td>0.644593</td>\n",
       "      <td>0.573772</td>\n",
       "      <td>0.281679</td>\n",
       "      <td>0.107912</td>\n",
       "      <td>0.121537</td>\n",
       "      <td>0.267066</td>\n",
       "      <td>0.277886</td>\n",
       "      <td>0.870772</td>\n",
       "      <td>...</td>\n",
       "      <td>0.722194</td>\n",
       "      <td>0.680168</td>\n",
       "      <td>0.685241</td>\n",
       "      <td>0.736108</td>\n",
       "      <td>0.912411</td>\n",
       "      <td>0.736572</td>\n",
       "      <td>0.713729</td>\n",
       "      <td>0.732448</td>\n",
       "      <td>0.723244</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 735 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   a-Cyclodextrin   Dextrin  Glycogen  Maltitol  Maltotriose   Maltose  \\\n",
       "0        0.423145  0.611943  0.673013  0.655346     0.798260  0.741404   \n",
       "1        0.354959  0.554366  0.692812  0.725226     0.754946  0.775075   \n",
       "2        0.568819  0.888562  1.000000  0.970318     0.214713  0.072198   \n",
       "3        0.204909  0.339476  0.239045  0.324258     0.125324  0.081788   \n",
       "4        0.396242  0.851239  0.644593  0.573772     0.281679  0.107912   \n",
       "\n",
       "   D-Trehalose  D-Cellobiose  Gentiobiose  D-Glucose-6-Phosphate  ...  \\\n",
       "0     0.599716      0.665656     0.754709               0.489498  ...   \n",
       "1     0.575320      0.703234     0.652358               0.503952  ...   \n",
       "2     0.333904      0.082914     0.306733               0.763727  ...   \n",
       "3     0.160053      0.184931     0.226685               0.277191  ...   \n",
       "4     0.121537      0.267066     0.277886               0.870772  ...   \n",
       "\n",
       "   Adenosine.4  Adenosine.5  Adenosine.6  Gly-His-Lys acetate salt  \\\n",
       "0     0.553747     0.529862     0.554927                  0.580709   \n",
       "1     0.597941     0.544887     0.644687                  0.558909   \n",
       "2     0.678014     0.341184     0.334388                  0.705864   \n",
       "3     0.278496     0.294307     0.260791                  0.347324   \n",
       "4     0.722194     0.680168     0.685241                  0.736108   \n",
       "\n",
       "   Gly-His-Lys acetate salt.1  Gly-His-Lys acetate salt.2  \\\n",
       "0                    0.632509                    0.616020   \n",
       "1                    0.537492                    0.568644   \n",
       "2                    0.712690                    0.710792   \n",
       "3                    0.334002                    0.360123   \n",
       "4                    0.912411                    0.736572   \n",
       "\n",
       "   Gly-His-Lys acetate salt.3  Gly-His-Lys acetate salt.4  \\\n",
       "0                    0.553273                    0.584858   \n",
       "1                    0.508922                    0.573468   \n",
       "2                    0.613200                    0.645610   \n",
       "3                    0.316979                    0.346016   \n",
       "4                    0.713729                    0.732448   \n",
       "\n",
       "   Gly-His-Lys acetate salt.5  Diagnosis  \n",
       "0                    0.574413        1.0  \n",
       "1                    0.585870        1.0  \n",
       "2                    0.467408        1.0  \n",
       "3                    0.355979        1.0  \n",
       "4                    0.723244        1.0  \n",
       "\n",
       "[5 rows x 735 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_data = scale_data(asd_data)\n",
    "transformed_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bbd4d64",
   "metadata": {
    "id": "6bbd4d64"
   },
   "source": [
    "5. Perform train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2c41cf1",
   "metadata": {
    "id": "c2c41cf1"
   },
   "outputs": [],
   "source": [
    "# select all rows of all columns except the column 'Diagnosis'\n",
    "X = transformed_data.loc[:, :'Gly-His-Lys acetate salt.5']\n",
    "\n",
    "# the column we are going to classify\n",
    "y = transformed_data['Diagnosis']\n",
    "\n",
    "# do the train test data split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=50)\n",
    "\n",
    "# convert y_train and y_test into dataframes\n",
    "y_train = pd.DataFrame(y_train)\n",
    "y_test = pd.DataFrame(y_test)\n",
    "\n",
    "y_train = y_train.astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93ae893",
   "metadata": {
    "id": "e93ae893"
   },
   "source": [
    "Writing a function which returns the list of k-Best features where k being the number of features required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7067f3ce",
   "metadata": {
    "id": "7067f3ce"
   },
   "outputs": [],
   "source": [
    "#use chi2\n",
    "def get_k_best_features(X_train, y_train, k):\n",
    "    \n",
    "    # use SelectKBest class to get k best features\n",
    "    X_best_features = SelectKBest(score_func=chi2, k=k)\n",
    "    z = X_best_features.fit_transform(X_train, y_train) \n",
    "    \n",
    "    # will return boolean indices\n",
    "    best_features_indices = X_best_features.get_support()\n",
    "    \n",
    "    best_features = []\n",
    "    \n",
    "    data_columns = X_train.columns\n",
    "    \n",
    "    for index, bool_value in enumerate(best_features_indices):\n",
    "        # append the best features to the best_features list\n",
    "        if(bool_value):\n",
    "          best_features.append(data_columns[index])\n",
    "    \n",
    "    return best_features\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfdeb22c",
   "metadata": {
    "id": "bfdeb22c"
   },
   "source": [
    "Print the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e30bc26b",
   "metadata": {
    "id": "e30bc26b"
   },
   "outputs": [],
   "source": [
    "features_one = get_k_best_features(X_train, y_train, 12)        \n",
    "features_two = get_k_best_features(X_train, y_train, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "453164a9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "453164a9",
    "outputId": "c112552a-7ae1-4003-b1eb-9cea8c4bc1c8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NaCl.2',\n",
       " 'Potassium Chloride.1',\n",
       " 'Potassium Chloride.2',\n",
       " 'Calcium Choride',\n",
       " 'Iodine',\n",
       " 'Iodine.1',\n",
       " 'Iodine.2',\n",
       " 'Sodium Molybdate.1',\n",
       " 'Sodium Molybdate.2',\n",
       " 'Potassium Chromate.1',\n",
       " 'Potassium Chromate.2',\n",
       " 'Sodium Nitrite.3']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38bddde3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "38bddde3",
    "outputId": "e52a8196-6486-4297-9a8a-b86e747704a4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D-Glucose-6-Phosphate',\n",
       " 'NaCl.2',\n",
       " 'Potassium Chloride.1',\n",
       " 'Potassium Chloride.2',\n",
       " 'Calcium Choride',\n",
       " 'Manganese Chloride.3',\n",
       " 'Cobalt Chloride.3',\n",
       " 'Iodine',\n",
       " 'Iodine.1',\n",
       " 'Iodine.2',\n",
       " 'Iodine.3',\n",
       " 'Sodium Molybdate',\n",
       " 'Sodium Molybdate.1',\n",
       " 'Sodium Molybdate.2',\n",
       " 'Potassium Chromate.1',\n",
       " 'Potassium Chromate.2',\n",
       " 'Potassium Chromate.3',\n",
       " 'Sodium Nitrite.1',\n",
       " 'Sodium Nitrite.3',\n",
       " 'Glucagon.3']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_two"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3HS3Pd64D8Ch",
   "metadata": {
    "id": "3HS3Pd64D8Ch"
   },
   "source": [
    "Feature selection is the process of identifying and selecting a set of relevant features or variables that are most useful for building an accurate prediction model. \n",
    "\n",
    "The code involves cleaning the data by dropping columns, taking care of whitespaces in names, and preprocessing it by scaling all features to a range, to prevent bias and normalize them. \n",
    "\n",
    "The data is then split into training data and testing data, and SelectKBest class is used to return *k* best features.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d376c650",
   "metadata": {
    "id": "d376c650"
   },
   "source": [
    "### perform Ridge regularization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1644ca38",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1644ca38",
    "outputId": "31f2d6dd-0f75-44c4-f35e-13e4b2bb3aef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Regression MSE:  0.24085228595702884\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "clf = Ridge(alpha=1.0)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred_ridge = clf.predict(X_test)\n",
    "mse_ridge = mean_squared_error(y_test, y_pred_ridge)\n",
    "print(\"Ridge Regression MSE: \", mse_ridge)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b325e790",
   "metadata": {
    "id": "b325e790"
   },
   "source": [
    "### perform Lasso regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a5fdbb0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6a5fdbb0",
    "outputId": "35838e78-aeec-4fc8-eda6-cc58f4886274"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Regression MSE:  0.25115646258503393\n"
     ]
    }
   ],
   "source": [
    "clf = Lasso(alpha=0.1)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred_lasso = clf.predict(X_test)\n",
    "mse_lasso = mean_squared_error(y_test, y_pred_lasso)\n",
    "print(\"Lasso Regression MSE: \", mse_lasso)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "o6sx9LRqCruA",
   "metadata": {
    "id": "o6sx9LRqCruA"
   },
   "source": [
    "As is evident here, Ridge regression works better in this case. Both Lasso and Ridge models add a penalty term to the regression equation to prevent overfitting and thus make for better prediction.\n",
    "\n",
    "Ridge model applies L2 regularization, i.e., it adds a factor of the sum of squares of coefficients in the optimization objective.\n",
    "\n",
    "LASSO stands for Least Absolute Shrinkage and Selection Operator, and performs L1 regularization, adding a factor of the sum of the absolute value of coefficients in the optimization objective.\n",
    "\n",
    "Ridge regression is better suited when all features in the model have predictive power, while Lasso is a good option when some features are less important or irrelevant, as it can help identify and remove them from the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e40da42d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.667 (0.081)\n"
     ]
    }
   ],
   "source": [
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "model = LogisticRegression()\n",
    "# evaluate model\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=1)\n",
    "n_scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a91ace31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4999999999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gsinha\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:680: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\gsinha\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:680: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\gsinha\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:680: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\gsinha\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:680: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\gsinha\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:680: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6142857142857142\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# evaluate an LDA model on the dataset using k-fold cross validation\n",
    "model = LinearDiscriminantAnalysis()\n",
    "kfold = KFold(n_splits=5, random_state=None)\n",
    "result = cross_val_score(model, X, y, cv=kfold, scoring='accuracy')\n",
    "print(result.mean())\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, recall_score, classification_report, cohen_kappa_score\n",
    "from sklearn import metrics \n",
    "\n",
    "# Baseline Random forest based Model\n",
    "rfc = RandomForestClassifier(n_estimators=200)\n",
    "    \n",
    "kfold = KFold(n_splits=5, random_state=None)\n",
    "result2 = cross_val_score(rfc, X_train, y_train, cv=kfold, scoring='accuracy')\n",
    "print(result2.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6ef9b4de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.699 (0.098)\n"
     ]
    }
   ],
   "source": [
    "# evaluate pca with logistic regression algorithm for classification\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# define dataset\n",
    "#X, y = make_classification(n_samples=1000, n_features=20, n_informative=10, n_redundant=10, random_state=7)\n",
    "# define the pipeline\n",
    "steps = [('pca', PCA(n_components=10)), ('m', LogisticRegression())]\n",
    "model = Pipeline(steps=steps)\n",
    "# evaluate model\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=100, random_state=1)\n",
    "n_scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "266de1e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:01<00:00, 18.14it/s]\n"
     ]
    }
   ],
   "source": [
    "#!pip install lazypredict\n",
    "from lazypredict.Supervised import LazyClassifier, LazyRegressor\n",
    "clf = LazyClassifier(predictions=True)\n",
    "models, predictions = clf.fit(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fc24c811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               Accuracy  Balanced Accuracy  ROC AUC  F1 Score  \\\n",
      "Model                                                                           \n",
      "LogisticRegression                 0.73               0.72     0.72      0.73   \n",
      "LinearDiscriminantAnalysis         0.70               0.69     0.69      0.69   \n",
      "LinearSVC                          0.70               0.69     0.69      0.69   \n",
      "RidgeClassifierCV                  0.70               0.69     0.69      0.69   \n",
      "PassiveAggressiveClassifier        0.70               0.69     0.69      0.69   \n",
      "CalibratedClassifierCV             0.67               0.66     0.66      0.66   \n",
      "RidgeClassifier                    0.67               0.65     0.65      0.65   \n",
      "SGDClassifier                      0.63               0.63     0.63      0.63   \n",
      "NearestCentroid                    0.63               0.63     0.63      0.63   \n",
      "AdaBoostClassifier                 0.63               0.63     0.63      0.63   \n",
      "LGBMClassifier                     0.63               0.62     0.62      0.63   \n",
      "NuSVC                              0.63               0.62     0.62      0.63   \n",
      "XGBClassifier                      0.63               0.62     0.62      0.63   \n",
      "Perceptron                         0.63               0.62     0.62      0.61   \n",
      "BaggingClassifier                  0.60               0.60     0.60      0.60   \n",
      "GaussianNB                         0.60               0.59     0.59      0.60   \n",
      "RandomForestClassifier             0.60               0.59     0.59      0.59   \n",
      "SVC                                0.60               0.59     0.59      0.59   \n",
      "ExtraTreesClassifier               0.57               0.55     0.55      0.55   \n",
      "ExtraTreeClassifier                0.53               0.54     0.54      0.53   \n",
      "BernoulliNB                        0.53               0.52     0.52      0.52   \n",
      "QuadraticDiscriminantAnalysis      0.53               0.52     0.52      0.51   \n",
      "LabelSpreading                     0.47               0.50     0.50      0.30   \n",
      "DummyClassifier                    0.47               0.50     0.50      0.30   \n",
      "LabelPropagation                   0.47               0.50     0.50      0.30   \n",
      "KNeighborsClassifier               0.47               0.46     0.46      0.46   \n",
      "DecisionTreeClassifier             0.47               0.46     0.46      0.45   \n",
      "\n",
      "                               Time Taken  \n",
      "Model                                      \n",
      "LogisticRegression                   0.05  \n",
      "LinearDiscriminantAnalysis           0.03  \n",
      "LinearSVC                            0.04  \n",
      "RidgeClassifierCV                    0.03  \n",
      "PassiveAggressiveClassifier          0.03  \n",
      "CalibratedClassifierCV               0.08  \n",
      "RidgeClassifier                      0.02  \n",
      "SGDClassifier                        0.02  \n",
      "NearestCentroid                      0.02  \n",
      "AdaBoostClassifier                   0.25  \n",
      "LGBMClassifier                       0.14  \n",
      "NuSVC                                0.03  \n",
      "XGBClassifier                        0.19  \n",
      "Perceptron                           0.02  \n",
      "BaggingClassifier                    0.08  \n",
      "GaussianNB                           0.02  \n",
      "RandomForestClassifier               0.18  \n",
      "SVC                                  0.02  \n",
      "ExtraTreesClassifier                 0.11  \n",
      "ExtraTreeClassifier                  0.02  \n",
      "BernoulliNB                          0.03  \n",
      "QuadraticDiscriminantAnalysis        0.04  \n",
      "LabelSpreading                       0.02  \n",
      "DummyClassifier                      0.03  \n",
      "LabelPropagation                     0.02  \n",
      "KNeighborsClassifier                 0.02  \n",
      "DecisionTreeClassifier               0.03  \n"
     ]
    }
   ],
   "source": [
    "print(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7914b92f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.628571 (0.204041)\n",
      "XGB: 0.542857 (0.166599)\n",
      "SVM: 0.314286 (0.166599)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier, VotingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "logreg= LogisticRegressionCV(solver='lbfgs', cv=10)\n",
    "knn = KNeighborsClassifier(5)\n",
    "svcl = SVC()\n",
    "adb = AdaBoostClassifier()\n",
    "dt = DecisionTreeClassifier(max_depth=5)\n",
    "rf = RandomForestClassifier()\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "gnb = GaussianNB()\n",
    "\n",
    "# prepare configuration for cross validation test harness\n",
    "seed = 7\n",
    "# prepare models\n",
    "models = []\n",
    "models.append(('LR', LogisticRegressionCV(solver='lbfgs', max_iter=5000, cv=10)))\n",
    "models.append(('XGB', XGBClassifier()))\n",
    "models.append(('SVM', SVC(gamma='auto')))\n",
    "results = []\n",
    "names = []\n",
    "scoring = 'f1'\n",
    "for name, model in models:\n",
    "    kfold = model_selection.KFold(n_splits=10, random_state=None)\n",
    "    cv_results = model_selection.cross_val_score(model, x_train_scaled, y_train, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85310eac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
